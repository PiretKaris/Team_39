{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;\f1\fnil\fcharset0 HelveticaNeue-Bold;\f2\fnil\fcharset0 HelveticaNeue-Italic;
}
{\colortbl;\red255\green255\blue255;\red22\green25\blue28;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c11373\c12941\c14510;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs30 \cf2 \cb3 \expnd0\expndtw0\kerning0
Task: This is a complicated topic, teamwork is to look at scikit-learn library together. Suggested questions to discuss:\
\
1. What is an error rate?\cb1 \
\cb3 2. Where you could use other machine-learning models?\cb1 \
\cb3 3. What is the difference between supervised and unsupervised training?\cb1 \
\cb3 4. How to import different models from the scikit-learn package?\cb1 \
\cb3 5. How can you evaluate the performance of a machine learning model in scikit-learn?\cb1 \
\cb3 6. What metrics are commonly used for evaluation?\cb1 \
\cb3 7. What is model overfitting, and how can it be prevented?\
\
\

\f1\b 3. \cf2 What is the difference between supervised and unsupervised training?
\f0\b0 \
\cf2 \
\ul * Supervised Training:\
\ulnone Labeled Data: In supervised learning, the training data includes both the input features (independent variables) and the corresponding output labels (dependent variables). These labels serve as the ground truth that the model tries to predict.\
The primary goal is to learn a mapping from inputs to outputs. The model is trained to predict the output labels given the input data by minimizing the difference between the predicted labels and the actual labels.\

\f2\i Examples in scikit-learn:\
Classification: Predicting a categorical label, such as identifying if an email is spam or not (e.g., RandomForestClassifier, SVC).\
Regression: Predicting a continuous value, such as forecasting house prices (e.g., LinearRegression, SVR).
\f0\i0 \
\
\ul * Unsupervised Training:\
\ulnone Unlabeled Data: In unsupervised learning, the training data consists only of input features without any corresponding output labels. The model tries to learn the underlying structure or distribution in the data.\
Goal: The main objective is to find patterns or groupings in the data, such as clustering similar data points or reducing the dimensionality of the data.\

\f2\i Examples in scikit-learn:\
Clustering: Grouping similar data points into clusters (e.g., KMeans, DBSCAN).\
Dimensionality Reduction: Reducing the number of input variables while preserving as much information as possible (e.g., PCA, t-SNE).\

\f0\i0 \
Summary:\
Supervised Learning involves training models on labeled data to make predictions.\
Unsupervised Learning involves identifying patterns or structures in unlabeled data without explicit guidance on the desired outcome.\
\

\f1\b 4. \cf2 How to import different models from the scikit-learn package?
\f0\b0 \
\cf2 \
To import different models from the scikit-learn package, you can use the import statement in Python. Scikit-learn organizes its models into different modules based on the type of algorithm (e.g., classification, regression, clustering). Below are some examples of how to import various models from scikit-learn:\
\
\ul 1. Classification Models\ulnone \
\pard\pardeftab720\partightenfactor0

\f2\i \cf2 Logistic Regression:
\f0\i0 \
\pard\pardeftab720\partightenfactor0
\cf2 from sklearn.linear_model import LogisticRegression\
\
\ul 2. Regression Models\ulnone \

\f2\i Linear Regression:\

\f0\i0 from sklearn.linear_model import LinearRegression\
\
\ul 3. Clustering Models\
\pard\pardeftab720\partightenfactor0

\f2\i \cf2 \ulnone K-Means Clustering:\

\f0\i0 from sklearn.cluster import KMeans\
\
\ul 4. Dimensionality Reduction\

\f2\i \ulnone Principal Component Analysis (PCA):\

\f0\i0 from sklearn.decomposition import PCA\
\
\ul 5. Model Selection and Evaluation\

\f2\i \ulnone Train-Test Split:\

\f0\i0 from sklearn.model_selection import train_test_split\
\
\ul 6. Preprocessing\

\f2\i \ulnone Standard Scaler:\

\f0\i0 from sklearn.preprocessing import StandardScaler\
}